#!/usr/bin/env python3
"""
Logwatch AI Analyzer
Analyzes logwatch output using OpenAI API and sends alerts only when issues are detected
"""

import os
import json
import subprocess
import logging
import smtplib
import time
import fcntl
import socket
from datetime import datetime, timedelta
from pathlib import Path
from typing import Optional, Dict, Any
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart

try:
    from openai import OpenAI
except ImportError:
    print("Error: OpenAI library not installed. Run: pip install openai")
    exit(1)

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/var/log/logwatch-ai.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class LogwatchAIAnalyzer:
    """Analyzes logwatch output using AI and sends notifications"""

    def __init__(self, config_path: str = "/etc/logwatch-ai/config.json"):
        """Initialize with configuration"""
        self.config = self.load_config(config_path)
        self.client = OpenAI(api_key=self.config['openai_api_key'])
        self.rate_limit_file = Path('/var/log/logwatch-ai-ratelimit.json')
        self.lock_file = Path('/var/lock/logwatch-ai.lock')

    def load_config(self, config_path: str) -> Dict[str, Any]:
        """Load configuration from JSON file"""
        config_file = Path(config_path)

        # Default configuration
        default_config = {
            "openai_api_key": os.getenv("OPENAI_API_KEY", ""),
            "openai_model": "gpt-4o-mini",
            "smtp_host": "localhost",
            "smtp_port": 25,
            "smtp_user": "",
            "smtp_password": "",
            "smtp_use_tls": False,
            "from_email": "logwatch-ai@localhost",
            "to_emails": ["root@localhost"],
            "alert_threshold": "medium",
            "logwatch_output_file": "/var/log/logwatch_output.txt",
            "always_send_summary": False,
            "max_requests_per_hour": 10,
            "max_requests_per_day": 50,
            "min_interval_minutes": 5,
            "max_retries": 3,
            "retry_delay_seconds": 30
        }

        if config_file.exists():
            try:
                with open(config_file, 'r') as f:
                    user_config = json.load(f)
                    default_config.update(user_config)
            except Exception as e:
                logger.warning(f"Failed to load config from {config_path}: {e}")

        return default_config

    def run_logwatch(self) -> str:
        """Execute logwatch and capture output"""
        try:
            result = subprocess.run(
                ['/usr/sbin/logwatch', '--output', 'stdout', '--format', 'text',
                 '--range', 'yesterday', '--detail', '10'],
                capture_output=True,
                text=True,
                timeout=60
            )

            if result.returncode != 0:
                logger.error(f"Logwatch failed with code {result.returncode}: {result.stderr}")
                return ""

            # Save raw output for debugging
            output_file = Path(self.config['logwatch_output_file'])
            output_file.parent.mkdir(parents=True, exist_ok=True)
            output_file.write_text(result.stdout)

            return result.stdout

        except Exception as e:
            logger.error(f"Failed to run logwatch: {e}")
            return ""

    def check_rate_limits(self) -> bool:
        """Check if we're within rate limits to prevent API abuse"""
        now = datetime.now()

        # Load existing rate limit data
        rate_data = {"requests": []}
        if self.rate_limit_file.exists():
            try:
                with open(self.rate_limit_file, 'r') as f:
                    rate_data = json.load(f)
            except Exception as e:
                logger.warning(f"Failed to load rate limit data: {e}")

        # Clean up old entries (older than 24 hours)
        cutoff_time = (now - timedelta(days=1)).isoformat()
        rate_data["requests"] = [
            req for req in rate_data["requests"]
            if req > cutoff_time
        ]

        # Check minimum interval since last request
        if rate_data["requests"]:
            last_request = datetime.fromisoformat(rate_data["requests"][-1])
            time_since_last = (now - last_request).total_seconds() / 60

            if time_since_last < self.config["min_interval_minutes"]:
                remaining = self.config["min_interval_minutes"] - time_since_last
                logger.warning(f"Rate limit: minimum interval not met. Wait {remaining:.1f} more minutes.")
                return False

        # Check hourly limit
        hour_ago = (now - timedelta(hours=1)).isoformat()
        hour_requests = sum(1 for req in rate_data["requests"] if req > hour_ago)

        if hour_requests >= self.config["max_requests_per_hour"]:
            logger.warning(f"Rate limit: hourly limit ({self.config['max_requests_per_hour']}) reached")
            return False

        # Check daily limit
        day_requests = len(rate_data["requests"])

        if day_requests >= self.config["max_requests_per_day"]:
            logger.warning(f"Rate limit: daily limit ({self.config['max_requests_per_day']}) reached")
            return False

        # Add current request to rate limit data
        rate_data["requests"].append(now.isoformat())

        # Save updated rate limit data
        try:
            self.rate_limit_file.parent.mkdir(parents=True, exist_ok=True)
            with open(self.rate_limit_file, 'w') as f:
                json.dump(rate_data, f)
        except Exception as e:
            logger.error(f"Failed to save rate limit data: {e}")

        return True

    def acquire_lock(self) -> Optional[Any]:
        """Acquire a file lock to prevent concurrent runs"""
        try:
            self.lock_file.parent.mkdir(parents=True, exist_ok=True)
            lock_fd = open(self.lock_file, 'w')
            fcntl.flock(lock_fd, fcntl.LOCK_EX | fcntl.LOCK_NB)
            return lock_fd
        except (IOError, OSError):
            logger.error("Another instance is already running. Exiting to prevent duplicate API calls.")
            return None

    def release_lock(self, lock_fd):
        """Release the file lock"""
        if lock_fd:
            try:
                fcntl.flock(lock_fd, fcntl.LOCK_UN)
                lock_fd.close()
            except Exception as e:
                logger.warning(f"Failed to release lock: {e}")

    def analyze_with_ai(self, log_content: str) -> Dict[str, Any]:
        """Analyze log content using OpenAI API with rate limiting and retries"""

        if not log_content:
            return {
                "severity": "error",
                "issues_found": True,
                "summary": "åˆ†æã™ã‚‹logwatchå‡ºåŠ›ãŒã‚ã‚Šã¾ã›ã‚“",
                "details": [],
                "recommendations": []
            }

        # Check rate limits before making API call
        if not self.check_rate_limits():
            return {
                "severity": "error",
                "issues_found": True,
                "summary": "ãƒ¬ãƒ¼ãƒˆåˆ¶é™è¶…é - APIéå‰°åˆ©ç”¨é˜²æ­¢ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸ",
                "critical_issues": ["ãƒ¬ãƒ¼ãƒˆåˆ¶é™ä¿è­·ãŒä½œå‹•ã—ã¾ã—ãŸ"],
                "warnings": [],
                "statistics": {},
                "recommendations": ["æ¬¡å›å®Ÿè¡Œã¾ã§å¾…ã¤ã‹ã€è¨­å®šã§ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’èª¿æ•´ã—ã¦ãã ã•ã„"]
            }

        prompt = f"""ã‚ãªãŸã¯Linuxã‚·ã‚¹ãƒ†ãƒ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®logwatchå‡ºåŠ›ã‚’åˆ†æã—ã€æ§‹é€ åŒ–ã•ã‚ŒãŸè©•ä¾¡ã‚’æ—¥æœ¬èªã§æä¾›ã—ã¦ãã ã•ã„ã€‚

ã€æœ€é‡è¦ã€‘æœ¬å½“ã«å¯¾å¿œãŒå¿…è¦ãªå•é¡Œã ã‘ã‚’å ±å‘Šã—ã¦ãã ã•ã„ã€‚ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆå…¬é–‹ã‚µãƒ¼ãƒãƒ¼ã§æ—¥å¸¸çš„ã«ç™ºç”Ÿã™ã‚‹äº‹è±¡ã¯å…¨ã¦ç„¡è¦–ã—ã¦ãã ã•ã„ã€‚

ä»¥ä¸‹ã¯ã€å®Œå…¨ã«ç„¡è¦–ã€‘ã—ã¦ãã ã•ã„ï¼ˆcritical_issuesã‚„warningsã«å«ã‚ãªã„ï¼‰ï¼š
- å¤±æ•—ã—ãŸSSHãƒ­ã‚°ã‚¤ãƒ³è©¦è¡Œï¼ˆãƒ–ãƒ­ãƒƒã‚¯æ¸ˆã¿ã®æ”»æ’ƒï¼‰
- 404/400/401ã‚¨ãƒ©ãƒ¼ã‚’è¿”ã—ãŸHTTPãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼ˆã‚¹ã‚­ãƒ£ãƒ³ãƒœãƒƒãƒˆã¯æ—¥å¸¸çš„ï¼‰
- /.envã€/.git/configã€/phpMyAdminç­‰ã¸ã®è„†å¼±æ€§ã‚¹ã‚­ãƒ£ãƒ³ï¼ˆå…¨ã¦å¤±æ•—ã—ã¦ã„ã‚‹ï¼‰
- "Attempts to use known hacks"ã®å ±å‘Šï¼ˆæ”»æ’ƒè©¦è¡Œã¯å¤±æ•—ã—ã¦ã„ã‚‹ï¼‰
- mod_proxyã¸ã®æ¥ç¶šè©¦è¡Œ
- fail2banã«ã‚ˆã‚‹ãƒ–ãƒ­ãƒƒã‚¯
- ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨ç‡85%æœªæº€
- é€šå¸¸ã®ã‚µãƒ¼ãƒ“ã‚¹å†èµ·å‹•
- å®šæœŸçš„ãªcronã‚¸ãƒ§ãƒ–å®Ÿè¡Œ
- ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®æ›´æ–°ãƒ»ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
- é€šå¸¸ã®ãƒ¡ãƒ¼ãƒ«é€å—ä¿¡

ä»¥ä¸‹ã®ã€æœ¬å½“ã«é‡å¤§ãªå•é¡Œã®ã¿ã€‘ã‚’critical_issuesã«å«ã‚ã¦ãã ã•ã„ï¼š
- èªè¨¼æˆåŠŸå¾Œã®ä¸å¯©ãªã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ï¼ˆãƒ­ã‚°ã‚¤ãƒ³æˆåŠŸ+ç•°å¸¸æ“ä½œï¼‰
- rootã‚„ç®¡ç†è€…ã§ã®äºˆæœŸã—ãªã„ãƒ­ã‚°ã‚¤ãƒ³æˆåŠŸ
- ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨ç‡85%è¶…é
- ã‚µãƒ¼ãƒ“ã‚¹ã®ç•°å¸¸åœæ­¢ãƒ»ã‚¯ãƒ©ãƒƒã‚·ãƒ¥ï¼ˆå†èµ·å‹•ã§ã¯ãªãåœæ­¢ï¼‰
- ã‚«ãƒ¼ãƒãƒ«ãƒ‘ãƒ‹ãƒƒã‚¯ã‚„OOMã‚­ãƒ©ãƒ¼ç™ºå‹•
- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ç ´æã‚„ã‚¯ãƒ©ãƒƒã‚·ãƒ¥
- ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼

severityåˆ¤å®šåŸºæº–ï¼š
- "none": å•é¡Œãªã—ï¼ˆæ—¥å¸¸çš„ãªã‚¹ã‚­ãƒ£ãƒ³ã®ã¿ï¼‰
- "low": è»½å¾®ãªæ³¨æ„äº‹é …ã®ã¿
- "medium": ç¢ºèªãŒå¿…è¦ã ãŒç·Šæ€¥ã§ã¯ãªã„
- "high": 24æ™‚é–“ä»¥å†…ã®å¯¾å¿œãŒå¿…è¦
- "critical": å³æ™‚å¯¾å¿œãŒå¿…è¦

JSONå½¢å¼ã§æ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ï¼š
{{
    "severity": "none|low|medium|high|critical",
    "issues_found": true|false,
    "summary": "ç°¡æ½”ãªä¸€è¡Œã‚µãƒãƒªãƒ¼",
    "critical_issues": ["å•é¡Œ1", "å•é¡Œ2"],
    "warnings": ["è­¦å‘Š1", "è­¦å‘Š2"],
    "statistics": {{
        "ssh_attempts": æ•°å€¤,
        "blocked_ips": æ•°å€¤,
        "disk_usage_percent": æ•°å€¤,
        "errors_count": æ•°å€¤
    }},
    "recommendations": ["æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³1", "æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³2"]
}}

Logwatchå‡ºåŠ›:
{log_content[:8000]}"""  # Limit to avoid token limits

        # Retry logic with exponential backoff
        last_error = None
        for attempt in range(self.config['max_retries']):
            try:
                response = self.client.chat.completions.create(
                    model=self.config['openai_model'],
                    messages=[
                        {"role": "system", "content": "ã‚ãªãŸã¯Linuxã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã®å°‚é–€å®¶ã§ã™ã€‚ç°¡æ½”ã§å®Ÿç”¨çš„ãªåˆ†æã‚’æ—¥æœ¬èªã§æä¾›ã—ã¦ãã ã•ã„ã€‚"},
                        {"role": "user", "content": prompt}
                    ],
                    # temperature=0,  # Removed - not supported by gpt-4o-mini
                    max_completion_tokens=1000,  # Changed from max_tokens to max_completion_tokens
                    response_format={"type": "json_object"},
                    timeout=30  # 30 second timeout per request
                )

                result = json.loads(response.choices[0].message.content)
                logger.info(f"AI Analysis complete. Severity: {result.get('severity', 'unknown')}")
                return result

            except Exception as e:
                last_error = e
                logger.warning(f"API call attempt {attempt + 1}/{self.config['max_retries']} failed: {e}")

                if attempt < self.config['max_retries'] - 1:
                    delay = self.config['retry_delay_seconds'] * (2 ** attempt)  # Exponential backoff
                    logger.info(f"Retrying in {delay} seconds...")
                    time.sleep(delay)

        # All retries failed
        logger.error(f"All API retry attempts failed. Last error: {last_error}")
        return {
            "severity": "error",
            "issues_found": True,
            "summary": f"AI analysis failed after {self.config['max_retries']} attempts: {str(last_error)}",
            "critical_issues": ["Failed to analyze logs with AI after multiple retries"],
            "warnings": [],
            "statistics": {},
            "recommendations": ["Check OpenAI API key, connectivity, and rate limits"]
        }

    def should_send_alert(self, analysis: Dict[str, Any]) -> bool:
        """Determine if an alert should be sent based on analysis"""
        if self.config['always_send_summary']:
            return True

        severity = analysis.get('severity', 'none')
        threshold = self.config['alert_threshold']

        severity_levels = {
            'none': 0,
            'low': 1,
            'medium': 2,
            'high': 3,
            'critical': 4,
            'error': 4
        }

        return severity_levels.get(severity, 0) >= severity_levels.get(threshold, 2)

    def format_email_body(self, analysis: Dict[str, Any], html: bool = True) -> str:
        """Format analysis results for email"""
        severity = analysis.get('severity', 'unknown').upper()
        severity_ja = {
            'NONE': 'æ­£å¸¸',
            'LOW': 'ä½',
            'MEDIUM': 'ä¸­',
            'HIGH': 'é«˜',
            'CRITICAL': 'ç·Šæ€¥',
            'ERROR': 'ã‚¨ãƒ©ãƒ¼'
        }
        emoji_map = {
            'NONE': 'âœ…',
            'LOW': 'ğŸ“‹',
            'MEDIUM': 'âš ï¸',
            'HIGH': 'ğŸ”´',
            'CRITICAL': 'ğŸš¨',
            'ERROR': 'âŒ'
        }
        emoji = emoji_map.get(severity, 'â“')
        severity_text = severity_ja.get(severity, severity)
        hostname = socket.gethostname()

        if html:
            body = f"""<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <style>
        body {{ font-family: 'Hiragino Sans', 'Yu Gothic', Arial, sans-serif; line-height: 1.6; }}
        .header {{ background: {'#d4edda' if severity == 'NONE' else '#f8d7da' if severity in ['HIGH', 'CRITICAL'] else '#fff3cd'};
                   padding: 15px; border-radius: 5px; margin-bottom: 20px; }}
        .severity {{ font-size: 24px; font-weight: bold; }}
        .section {{ margin: 20px 0; }}
        .issues {{ background: #f8f9fa; padding: 10px; border-left: 4px solid #dc3545; }}
        .warnings {{ background: #f8f9fa; padding: 10px; border-left: 4px solid #ffc107; }}
        .stats {{ background: #e9ecef; padding: 10px; border-radius: 5px; }}
        ul {{ margin: 10px 0; }}
    </style>
</head>
<body>
    <div class="header">
        <div class="severity">{emoji} é‡è¦åº¦: {severity_text}</div>
        <div>ãƒ›ã‚¹ãƒˆ: {hostname}</div>
        <div>æ—¥æ™‚: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}</div>
    </div>

    <div class="section">
        <h2>ğŸ“ æ¦‚è¦</h2>
        <p>{analysis.get('summary', 'æ¦‚è¦æƒ…å ±ãŒã‚ã‚Šã¾ã›ã‚“')}</p>
    </div>
"""

            if analysis.get('critical_issues'):
                body += """
    <div class="section issues">
        <h3>ğŸš¨ ç·Šæ€¥å¯¾å¿œãŒå¿…è¦ãªå•é¡Œ</h3>
        <ul>"""
                for issue in analysis['critical_issues']:
                    body += f"\n            <li>{issue}</li>"
                body += """
        </ul>
    </div>"""

            if analysis.get('warnings'):
                body += """
    <div class="section warnings">
        <h3>âš ï¸ è­¦å‘Š</h3>
        <ul>"""
                for warning in analysis['warnings']:
                    body += f"\n            <li>{warning}</li>"
                body += """
        </ul>
    </div>"""

            if analysis.get('statistics'):
                body += """
    <div class="section stats">
        <h3>ğŸ“Š çµ±è¨ˆæƒ…å ±</h3>
        <ul>"""
                stats_ja = {
                    'ssh_attempts': 'SSHè©¦è¡Œå›æ•°',
                    'blocked_ips': 'ãƒ–ãƒ­ãƒƒã‚¯ã•ã‚ŒãŸIPæ•°',
                    'disk_usage_percent': 'ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨ç‡(%)',
                    'errors_count': 'ã‚¨ãƒ©ãƒ¼æ•°'
                }
                for key, value in analysis['statistics'].items():
                    label = stats_ja.get(key, key.replace('_', ' ').title())
                    body += f"\n            <li><strong>{label}:</strong> {value}</li>"
                body += """
        </ul>
    </div>"""

            if analysis.get('recommendations'):
                body += """
    <div class="section">
        <h3>ğŸ’¡ æ¨å¥¨å¯¾å¿œ</h3>
        <ul>"""
                for rec in analysis['recommendations']:
                    body += f"\n            <li>{rec}</li>"
                body += """
        </ul>
    </div>"""

            body += """
</body>
</html>"""
        else:
            # Plain text version
            body = f"""{emoji} LOGWATCH AI åˆ†æçµæœ - {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}
{'=' * 60}
ãƒ›ã‚¹ãƒˆ: {hostname}
é‡è¦åº¦: {severity_text}
æ¦‚è¦: {analysis.get('summary', 'æ¦‚è¦æƒ…å ±ãŒã‚ã‚Šã¾ã›ã‚“')}

"""
            if analysis.get('critical_issues'):
                body += "ğŸš¨ ç·Šæ€¥å¯¾å¿œãŒå¿…è¦ãªå•é¡Œ:\n"
                for issue in analysis['critical_issues']:
                    body += f"  â€¢ {issue}\n"
                body += "\n"

            if analysis.get('warnings'):
                body += "âš ï¸ è­¦å‘Š:\n"
                for warning in analysis['warnings']:
                    body += f"  â€¢ {warning}\n"
                body += "\n"

            if analysis.get('statistics'):
                body += "ğŸ“Š çµ±è¨ˆæƒ…å ±:\n"
                stats_ja = {
                    'ssh_attempts': 'SSHè©¦è¡Œå›æ•°',
                    'blocked_ips': 'ãƒ–ãƒ­ãƒƒã‚¯ã•ã‚ŒãŸIPæ•°',
                    'disk_usage_percent': 'ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨ç‡(%)',
                    'errors_count': 'ã‚¨ãƒ©ãƒ¼æ•°'
                }
                for key, value in analysis['statistics'].items():
                    label = stats_ja.get(key, key.replace('_', ' ').title())
                    body += f"  â€¢ {label}: {value}\n"
                body += "\n"

            if analysis.get('recommendations'):
                body += "ğŸ’¡ æ¨å¥¨å¯¾å¿œ:\n"
                for rec in analysis['recommendations']:
                    body += f"  â€¢ {rec}\n"

        return body

    def send_email(self, analysis: Dict[str, Any]) -> bool:
        """Send email notification"""
        try:
            severity = analysis.get('severity', 'unknown').upper()
            severity_ja = {
                'NONE': 'æ­£å¸¸',
                'LOW': 'ä½',
                'MEDIUM': 'ä¸­',
                'HIGH': 'é«˜',
                'CRITICAL': 'ç·Šæ€¥',
                'ERROR': 'ã‚¨ãƒ©ãƒ¼'
            }
            emoji_map = {
                'NONE': 'âœ…',
                'LOW': 'ğŸ“‹',
                'MEDIUM': 'âš ï¸',
                'HIGH': 'ğŸ”´',
                'CRITICAL': 'ğŸš¨',
                'ERROR': 'âŒ'
            }
            emoji = emoji_map.get(severity, 'â“')
            severity_text = severity_ja.get(severity, severity)

            msg = MIMEMultipart('alternative')
            hostname = socket.gethostname()
            msg['Subject'] = f"{emoji} [{hostname}] Logwatch AI ãƒ¬ãƒãƒ¼ãƒˆ - é‡è¦åº¦: {severity_text} - {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')}"
            msg['From'] = self.config['from_email']
            msg['To'] = ', '.join(self.config['to_emails'])

            # Add both plain text and HTML versions
            text_part = MIMEText(self.format_email_body(analysis, html=False), 'plain')
            html_part = MIMEText(self.format_email_body(analysis, html=True), 'html')

            msg.attach(text_part)
            msg.attach(html_part)

            # Send email
            # Port 465 uses SSL, not STARTTLS
            if self.config['smtp_port'] == 465:
                smtp = smtplib.SMTP_SSL(self.config['smtp_host'], self.config['smtp_port'])
            else:
                smtp = smtplib.SMTP(self.config['smtp_host'], self.config['smtp_port'])
                if self.config['smtp_use_tls']:
                    smtp.starttls()

            if self.config['smtp_user'] and self.config['smtp_password']:
                smtp.login(self.config['smtp_user'], self.config['smtp_password'])

            smtp.send_message(msg)
            smtp.quit()

            logger.info(f"Email sent successfully to {self.config['to_emails']}")
            return True

        except Exception as e:
            logger.error(f"Failed to send email: {e}")
            return False

    def run(self) -> None:
        """Main execution method with concurrency protection"""
        logger.info("Starting Logwatch AI analysis")

        # Acquire lock to prevent concurrent runs
        lock_fd = self.acquire_lock()
        if not lock_fd:
            logger.error("Could not acquire lock - another instance may be running")
            return

        try:
            # Run logwatch
            logger.info("Running logwatch...")
            log_content = self.run_logwatch()

            if not log_content:
                logger.error("No logwatch output to analyze")
                return

            # Analyze with AI
            logger.info("Analyzing logs with AI...")
            analysis = self.analyze_with_ai(log_content)

            # Save analysis results
            analysis_file = Path('/var/log/logwatch-ai-analysis.json')
            analysis_file.write_text(json.dumps(analysis, indent=2))

            # Send alert if needed
            if self.should_send_alert(analysis):
                logger.info(f"Sending alert email (severity: {analysis.get('severity', 'unknown')})")
                self.send_email(analysis)
            else:
                logger.info(f"No alert needed (severity: {analysis.get('severity', 'unknown')})")

            logger.info("Logwatch AI analysis complete")

        finally:
            # Always release lock
            self.release_lock(lock_fd)

def main():
    """Main entry point"""
    try:
        analyzer = LogwatchAIAnalyzer()
        analyzer.run()
    except Exception as e:
        logger.error(f"Fatal error: {e}")
        exit(1)

if __name__ == "__main__":
    main()